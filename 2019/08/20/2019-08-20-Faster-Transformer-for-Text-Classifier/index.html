<!-- build time:Thu Jul 16 2020 17:45:50 GMT+0800 (China Standard Time) --><!doctype html><html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>NVIDIA Faster Transformer加速模型探究 - Joven Chu Blog</title><meta description="AI,NLP,开源,知识图谱,智能对话,商品推荐"><meta property="og:type" content="blog"><meta property="og:title" content="Joven Chu"><meta property="og:url" content="/"><meta property="og:site_name" content="Joven Chu"><meta property="og:description" content="AI,NLP,开源,知识图谱,智能对话,商品推荐"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="/img/header.png"><meta property="article:published_time" content="2019-08-20T04:00:25.000Z"><meta property="article:modified_time" content="2020-06-17T09:48:09.829Z"><meta property="article:author" content="Joven Chu"><meta property="article:tag" content="Bert"><meta property="article:tag" content="Transformer acceleration"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/header.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/"},"headline":"Joven Chu","image":["/img/header.png"],"datePublished":"2019-08-20T04:00:25.000Z","dateModified":"2020-06-17T09:48:09.829Z","author":{"@type":"Person","name":"Joven Chu"},"description":"AI,NLP,开源,知识图谱,智能对话,商品推荐"}</script><link rel="canonical" href="https://jovenchu.github.io/2019/08/20/2019-08-20-Faster-Transformer-for-Text-Classifier/"><link rel="alternative" href="/atom.xml" title="Joven Chu Blog" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"></head><body class="is-2-column"><script type="text/javascript" src="/js/theme-night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Joven Chu Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/JovenChu"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfvfj8szrij30rs0ikjtt.jpg" alt="NVIDIA Faster Transformer加速模型探究"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" datetime="2019-08-20T04:00:25.000Z" title="2019-08-20T04:00:25.000Z">2019-08-20</time><span class="level-item"><a class="link-muted" href="/categories/SOTA-Analysis/">SOTA Analysis</a></span><span class="level-item">7 分钟 读完 (大约 1083 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">NVIDIA Faster Transformer加速模型探究</h1><div class="content"><ul><li><p>实验原理：使用 NVIDIA开源的 Faster Transformer模型，对基于Bert的fine tune任务———单一文本分类进行训练和预测的加速。</p></li><li><p>实验结果：fasterTF-bert模型在文本预测任务上取得两倍于原始tensorflow-bert模型的速度，将极大的帮助到产品速度要求高的问答机器人等的快速落地。</p></li><li><p>项目地址： <a href="https://github.com/JovenChu/FasterTransformer_Bert">https://github.com/JovenChu/FasterTransformer_Bert</a></p></li></ul><a id="more"></a><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><ol><li><p>Modify the original code of <a href="https://github.com/google-research/bert">bert-master</a>:</p><ul><li><p>Copy the code of <a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/FasterTransformer/sample/tensorflow_bert">tensorflow_bert</a> to <a href="https://github.com/google-research/bert">Bert-master</a> path.</p></li><li><p>Copy the file of <a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/FasterTransformer">Faster Transformer</a> to <a href="https://github.com/google-research/bert">Bert-master</a> path.</p></li><li><p>Collection bert-base model <strong>uncased_L-12_H-768_A-12</strong> and test classifier data set <strong>IMDB</strong> by processing to <code>.tsv</code> format</p></li><li><p>Add the code of loding the train/dev/test data set in <code>run_classifier.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImdbProcessor</span><span class="params">(DataProcessor)</span>:</span></span><br><span class="line">  <span class="string">"""Processor for the IMDB data set."""</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_train_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">    <span class="string">"""See base class."""</span></span><br><span class="line">    <span class="keyword">return</span> self._create_examples(</span><br><span class="line">        self._read_tsv(os.path.join(data_dir, <span class="string">"train.tsv"</span>)), <span class="string">"train"</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_dev_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">    <span class="string">"""See base class."""</span></span><br><span class="line">    <span class="keyword">return</span> self._create_examples(</span><br><span class="line">        self._read_tsv(os.path.join(data_dir, <span class="string">"dev.tsv"</span>)), <span class="string">"dev"</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_test_examples</span><span class="params">(self, data_dir)</span>:</span></span><br><span class="line">    <span class="string">"""See base class."""</span></span><br><span class="line">    <span class="keyword">return</span> self._create_examples(</span><br><span class="line">        self._read_tsv(os.path.join(data_dir, <span class="string">"test.tsv"</span>)), <span class="string">"test"</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_labels</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""See base class."""</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">"pos"</span>, <span class="string">"neg"</span>]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_create_examples</span><span class="params">(self, lines, set_type)</span>:</span></span><br><span class="line">    <span class="string">"""Creates examples for the training and dev sets."""</span></span><br><span class="line">    <span class="comment"># get the examples of IMDB data</span></span><br><span class="line">    examples = []</span><br><span class="line">    <span class="keyword">for</span> (i, line) <span class="keyword">in</span> enumerate(lines):</span><br><span class="line">      <span class="keyword">if</span> set_type == <span class="string">"test"</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      guid = <span class="string">"%s-%s"</span> % (set_type, i)</span><br><span class="line">      <span class="keyword">if</span> set_type == <span class="string">"test"</span>:</span><br><span class="line">        text_a = tokenization.convert_to_unicode(line[<span class="number">1</span>])</span><br><span class="line">        label = <span class="string">"0"</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        text_a = tokenization.convert_to_unicode(line[<span class="number">1</span>])</span><br><span class="line">        label = tokenization.convert_to_unicode(line[<span class="number">0</span>])</span><br><span class="line">      examples.append(</span><br><span class="line">          InputExample(guid=guid, text_a=text_a, text_b=<span class="literal">None</span>, label=label))</span><br><span class="line">    <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure></li><li><p>Add the code of counting the time of train/evaluation/predict in <code>run_classifier.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> FLAGS.do_train:</span><br><span class="line">    train_file = os.path.join(FLAGS.output_dir, <span class="string">"train.tf_record"</span>)</span><br><span class="line">    file_based_convert_examples_to_features(</span><br><span class="line">        train_examples, label_list, FLAGS.max_seq_length, tokenizer, train_file)</span><br><span class="line">    tf.logging.info(<span class="string">"***** Running training *****"</span>)</span><br><span class="line">    tf.logging.info(<span class="string">"  Num examples = %d"</span>, len(train_examples))</span><br><span class="line">    tf.logging.info(<span class="string">"  Batch size = %d"</span>, FLAGS.train_batch_size)</span><br><span class="line">    tf.logging.info(<span class="string">"  Num steps = %d"</span>, num_train_steps)</span><br><span class="line">    train_input_fn = file_based_input_fn_builder(</span><br><span class="line">        input_file=train_file,</span><br><span class="line">        seq_length=FLAGS.max_seq_length,</span><br><span class="line">        is_training=<span class="literal">True</span>,</span><br><span class="line">        drop_remainder=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#  counting the time of train</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)</span><br><span class="line">    elapsed = time.time() - start</span><br><span class="line">    print(<span class="string">"training finished, time used:&#123;&#125;,average &#123;&#125; per sample"</span>.format(elapsed, elapsed/len(train_examples)))</span><br></pre></td></tr></table></figure></li></ul></li></ol><ol start="2"><li><p>Environment requirements:</p><ul><li><p>Create environment:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n fastertf2 python&#x3D;3.6</span><br><span class="line">source activate fastertf2</span><br></pre></td></tr></table></figure></li><li><p>CMake &gt;= 3.8</p><ul><li>pip install CMake -i <a href="https://pypi.douban.com/simple">https://pypi.douban.com/simple</a></li></ul></li><li><p>CUDA 10.0 &amp;&amp; CUDNN 7.3.1 &amp;&amp; NVIDIA RTX2080Ti</p><ul><li><p>Install：<a href="https://blog.csdn.net/qq_39418067/article/details/87978848">https://blog.csdn.net/qq_39418067/article/details/87978848</a></p></li><li><p>check：<code>nvcc -V</code> &amp;&amp; <code>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</code></p></li></ul></li><li><p>Tensorflow 1.13</p><ul><li>pip install Tensorflow-gpu==1.13.1 -i <a href="https://pypi.douban.com/simple">https://pypi.douban.com/simple</a></li></ul></li></ul></li><li><p>Build with Release:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> text_classifier/faster_transformer/fastertf_bert/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir -p build</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> build</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cmake -DSM=60 -DCMAKE_BUILD_TYPE=Release -DBUILD_TF=ON -DTF_PATH=/home/jovenchu/anaconda3/envs/fastertf2/lib/python3.6/site-packages/tensorflow .. <span class="comment"># Tensorflow mode</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> make</span></span><br></pre></td></tr></table></figure><ul><li><p>Generate optimized <strong>GEMM</strong> algorithm file. For batch_size=16, sequence length=128, head_num=12, size_per_head=64，use the script below</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ./bin/gemm_fp32 16 128 12 64</span></span><br></pre></td></tr></table></figure></li><li><p>Inferencing</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> BERT_BASE_DIR=<span class="string">'/home/jovenchu/text_classifier/faster_transformer/uncased_L-12_H-768_A-12'</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> IMDB_DIR=<span class="string">'/home/jovenchu/text_classifier/faster_transformer/data'</span></span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>Parameter setting：</p><ul><li>max_seq_length：128</li><li>train_batch_size：16</li><li>eval_batch_size：16</li><li>predict_batch_size：16</li><li>learning_rate：5e-5</li><li>num_train_epochs：1.0</li><li>save_checkpoints_steps：100</li><li>buffer_size = 2000 (match your sample size of training data,modify in run_classifier.py)</li></ul></li><li><p>Running:</p><ul><li><p>Training：We can’t use Faster Transformer to training model because of the Faster Transformer only support for FP16 (Half precision)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> python run_classifier.py   --task_name=Imdb   --do_train=<span class="literal">true</span>  --data_dir=<span class="variable">$IMDB_DIR</span>   --vocab_file=<span class="variable">$BERT_BASE_DIR</span>/vocab.txt   --bert_config_file=<span class="variable">$BERT_BASE_DIR</span>/bert_config.json   --max_seq_length=128   --eval_batch_size=16   --output_dir=imdb_output</span></span><br></pre></td></tr></table></figure></li><li><p>Evaluation：</p><ul><li><p>FP32 Tensorflow checkpoint files cannot be used directly for FP16 inference, we can convert its data type to FP16 in advance. The <code>ckpt_type_convert.py</code> script is provided for checkpoint data type conversion.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> python ckpt_type_convert.py --init_checkpoint=imdb_output/model.ckpt-125 --fp16_checkpoint=imdb_output/fp16_model.ckpt</span></span><br></pre></td></tr></table></figure></li><li><p>Running Evaluation code:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> python run_classifier.py   --task_name=Imdb   --do_eval=<span class="literal">true</span>   --data_dir=<span class="variable">$IMDB_DIR</span>   --vocab_file=<span class="variable">$BERT_BASE_DIR</span>/vocab.txt   --bert_config_file=<span class="variable">$BERT_BASE_DIR</span>/bert_config.json   --init_checkpoint=imdb_output/model.ckpt-125   --max_seq_length=128   --eval_batch_size=16   --output_dir=imdb_output</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> python run_classifier_fastertf.py   --task_name=Imdb   --do_eval=<span class="literal">true</span>   --data_dir=<span class="variable">$IMDB_DIR</span>   --vocab_file=<span class="variable">$BERT_BASE_DIR</span>/vocab.txt   --bert_config_file=<span class="variable">$BERT_BASE_DIR</span>/bert_config.json   --init_checkpoint=imdb_output/fp16_model.ckpt   --max_seq_length=128   --eval_batch_size=16   --output_dir=imdb_output   --floatx=float16</span></span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ol><h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><ul><li><p>Bert_train:</p><p>INFO:tensorflow:<strong><strong>* Running training *</strong></strong></p><p>INFO:tensorflow: Num examples = 2000</p><p>INFO:tensorflow: Batch size = 16</p><p>INFO:tensorflow: Num steps = 125</p><p>INFO:tensorflow:Loss for final step: 0.6994.</p><p>training finished, time used:57.629658222198486,average 0.028814829111099245 per sample</p></li><li><p>Bert_evaluation：</p><p>evaluation finished, time used:11.677468538284302,average 0.005838734269142151 per sample</p><p>INFO:tensorflow:<strong><strong>* Eval results *</strong></strong></p><p>INFO:tensorflow: eval_accuracy = 0.5</p><p>INFO:tensorflow: eval_loss = 0.69381195</p><p>INFO:tensorflow: global_step = 375</p><p>INFO:tensorflow: loss = 0.69381195</p></li><li><p>FasterTF_evaluation：</p><p>evaluation finished, time used:5.24286961555481,average 0.0026214348077774046 per sample</p><p>INFO:tensorflow:<strong><strong>* Eval results *</strong></strong></p><p>INFO:tensorflow: eval_accuracy = 0.5</p><p>INFO:tensorflow: eval_loss = 0.69376516</p><p>INFO:tensorflow: global_step = 375</p><p>INFO:tensorflow: loss = 0.69367576</p></li><li><p>Summary of experimental results ：</p><p><img src="http://ww4.sinaimg.cn/large/006tNc79gy1g664hiiaojj31dv0c20un.jpg" alt="image-20190820142234262"><br><font size="2" color="gray">Note: The experimental configuration is 11G Nvidia RTX2080Ti, Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz, 16G RAM, 2T hard disk</font></p></li></ul></div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Bert/">Bert</a><a class="link-muted mr-2" rel="tag" href="/tags/Transformer-acceleration/">Transformer acceleration</a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><div class="social-share"></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><ul class="post-copyright"><li><strong>本文标题：</strong><a href="https://jovenchu.github.io/2019/08/20/2019-08-20-Faster-Transformer-for-Text-Classifier/">NVIDIA Faster Transformer加速模型探究</a></li><li><strong>本文作者：</strong><a href="https://jovenchu.github.io">Joven Chu</a></li><li><strong>本文链接：</strong><a id="artTitle" href="https://jovenchu.github.io/2019/08/20/2019-08-20-Faster-Transformer-for-Text-Classifier/">https://jovenchu.github.io/2019/08/20/2019-08-20-Faster-Transformer-for-Text-Classifier/</a></li><li><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</span></li></ul><script>window.onload=function(){var n=window.document.location.href,t=window.document.location.pathname,o=n.indexOf(t),i=n.substring(0,o),a=$("#artTitle").html().substring(25);$("#artTitle").html(i+"/"+a)}</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay.jpg" alt="支付宝"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechatpay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/08/22/2019-08-22-NLP-Model-Analysis-Bert/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">NLP模型分析系列——BERT</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/03/30/2019-03-30-NLP-note/"><span class="level-item">NLP知识要点总结</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config=function(){this.page.url="https://jovenchu.github.io/2019/08/20/2019-08-20-Faster-Transformer-for-Text-Classifier/",this.page.identifier="2019/08/20/2019-08-20-Faster-Transformer-for-Text-Classifier/"};!function(){var e=document,t=e.createElement("script");t.src="//jovenchu.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}()</script></div></div></div><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen order-3"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#Model"><span class="mr-2">1</span><span>Model</span></a></li><li><a class="is-flex" href="#Result"><span class="mr-2">2</span><span>Result</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img src="/images/jovens.png" alt="Joven Chu"></figure><p class="title is-size-4 is-block line-height-inherit">Joven Chu</p><p class="is-size-6 is-block">The Alchemist of AI</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shenzhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JovenChu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/JovenChu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/profile.php?id=100009189950558"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/Qomolangma03"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/jovenchu233/"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget"><link href="/music/APlayer.min.css"><div id="aplayer" style="margin:0 auto"></div><script src="/music/APlayer.min.js"></script><script src="/music/APlayer_Music.js"></script></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><a class="media-left" href="/2020/07/16/2020-07-16-Chinese-Couplet/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggsw3l7ybwj31400u0kjl.jpg" alt="基于Seq2Seq的中文对联生成模型"></p></a><div class="media-content size-small"><p><time datetime="2020-07-16T08:14:18.000Z">2020-07-16</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/16/2020-07-16-Chinese-Couplet/">基于Seq2Seq的中文对联生成模型</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Text-Generation/">Text Generation</a></p></div></article><article class="media"><a class="media-left" href="/2020/06/09/2020-06-09-BiLSTM-CRF/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm5d5m5koj318z0u0b2a.jpg" alt="BiLSTM-CRF模型代码分析及CRF回顾"></p></a><div class="media-content size-small"><p><time datetime="2020-06-09T08:51:32.000Z">2020-06-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/09/2020-06-09-BiLSTM-CRF/">BiLSTM-CRF模型代码分析及CRF回顾</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/SOTA-Analysis/">SOTA Analysis</a></p></div></article><article class="media"><a class="media-left" href="/2019/10/22/2019-10-22-Information-Extraction-Chinese/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/006y8mN6gy1g86qm6jxacj30rs0ij75k.jpg" alt="基于Bert-NER构建特定领域的中文信息抽取框架"></p></a><div class="media-content size-small"><p><time datetime="2019-10-22T01:39:47.000Z">2019-10-22</time></p><p class="title is-6"><a class="link-muted" href="/2019/10/22/2019-10-22-Information-Extraction-Chinese/">基于Bert-NER构建特定领域的中文信息抽取框架</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Information-Extraction/">Information Extraction</a></p></div></article><article class="media"><a class="media-left" href="/2019/10/17/2019-10-17-AutoNLP-Analysis/"><p class="image is-64x64"><img class="thumbnail" src="https://images.unsplash.com/reserve/L55hYy77SLqb6zeTMlWr_IMG_9035.jpg?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1000&amp;q=80" alt="AutoNLP_Analysis"></p></a><div class="media-content size-small"><p><time datetime="2019-10-17T06:55:58.000Z">2019-10-17</time></p><p class="title is-6"><a class="link-muted" href="/2019/10/17/2019-10-17-AutoNLP-Analysis/">AutoNLP_Analysis</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/AutoNLP/">AutoNLP</a></p></div></article><article class="media"><a class="media-left" href="/2019/10/11/2019-10-11-Knowledge-Graph-Bert/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7u2cla0jsj31h90u0x6r.jpg" alt="Knowledge_Graph_Bert"></p></a><div class="media-content size-small"><p><time datetime="2019-10-11T02:45:08.000Z">2019-10-11</time></p><p class="title is-6"><a class="link-muted" href="/2019/10/11/2019-10-11-Knowledge-Graph-Bert/">Knowledge_Graph_Bert</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Knowledge-Graph/">Knowledge Graph</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/AutoNLP/"><span class="level-start"><span class="level-item">AutoNLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ElasticSearch/"><span class="level-start"><span class="level-item">ElasticSearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Information-Extraction/"><span class="level-start"><span class="level-item">Information Extraction</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Knowledge-Graph/"><span class="level-start"><span class="level-item">Knowledge Graph</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="level-start"><span class="level-item">NLP基础知识</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/SOTA-Analysis/"><span class="level-start"><span class="level-item">SOTA Analysis</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Text-Generation/"><span class="level-start"><span class="level-item">Text Generation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%AD%A6%E4%B9%A0%E5%8D%9A%E5%AE%A2/"><span class="level-start"><span class="level-item">学习博客</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item">对话系统</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">七月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">六月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/09/"><span class="level-start"><span class="level-item">九月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Joven Chu Blog" height="28"></a><p class="size-small">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> base on <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a></p></div><div class="level-mid"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/JovenChu"><i class="fab fa-github"></i></a></p></div></div><div class="level-end"><p class="size-small"><span><span id="statistic-times">loading...</span><script>function createTime(n){var m=new Date(n);now.setTime(now.getTime()+250),days=(now-m)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-m)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-m)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-m)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("statistic-times").innerHTML="♥ Security Run For <strong>"+dnum+"</strong> Days <strong>"+hnum+"</strong> Hours <strong>"+mnum+"</strong> Min <strong>"+snum+"</strong> Sec ♥"}var now=new Date;setInterval("createTime('12/31/2018 00:00:00')",250,"")</script><br></span></p><div class="size-small"><span>♥ Thanks For <strong><span id="busuanzi_value_site_uv">99+</span></strong> Visitors Come To My Site ♥</span></div><p></p></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN")</script><script>var IcarusThemeSettings={site:{url:"https://jovenchu.github.io",external_link:{enable:!0,exclude:[]}},article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><canvas class="fireworks" width="100%" height="100%" style="position:fixed;left:0;top:0;z-index:99999999;pointer-events:none"></canvas><script src="/js/anime.min.js" defer></script><script src="/js/fireworks.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script src="/js/main.js" defer></script><script src="/js/universe.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"想要查找什么...",untitled:"(无标题)",posts:"文章",pages:"页面",categories:"分类",tags:"标签"})})</script></body></html><!-- rebuild by neat -->