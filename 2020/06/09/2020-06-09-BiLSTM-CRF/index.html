<!-- build time:Wed Jul 22 2020 16:19:31 GMT+0800 (China Standard Time) --><!doctype html><html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>BiLSTM-CRF模型代码分析及CRF回顾 - Joven Chu Blog</title><meta description="AI,NLP,开源,知识图谱,智能对话,商品推荐"><meta property="og:type" content="blog"><meta property="og:title" content="Joven Chu"><meta property="og:url" content="/"><meta property="og:site_name" content="Joven Chu"><meta property="og:description" content="AI,NLP,开源,知识图谱,智能对话,商品推荐"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="/img/header.png"><meta property="article:published_time" content="2020-06-09T08:51:32.000Z"><meta property="article:modified_time" content="2020-06-09T09:06:07.048Z"><meta property="article:author" content="Joven Chu"><meta property="article:tag" content="BiLSTM"><meta property="article:tag" content="CRF"><meta property="article:tag" content="NER"><meta property="article:tag" content="NLP Model Analysis"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/header.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/"},"headline":"Joven Chu","image":["/img/header.png"],"datePublished":"2020-06-09T08:51:32.000Z","dateModified":"2020-06-09T09:06:07.048Z","author":{"@type":"Person","name":"Joven Chu"},"description":"AI,NLP,开源,知识图谱,智能对话,商品推荐"}</script><link rel="canonical" href="https://jovenchu.github.io/2020/06/09/2020-06-09-BiLSTM-CRF/"><link rel="alternative" href="/atom.xml" title="Joven Chu Blog" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"></head><body class="is-2-column"><script type="text/javascript" src="/js/theme-night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Joven Chu Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/friend">友链</a><a class="navbar-item" href="/about">关于我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/JovenChu"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm5d5m5koj318z0u0b2a.jpg" alt="BiLSTM-CRF模型代码分析及CRF回顾"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" datetime="2020-06-09T08:51:32.000Z" title="2020-06-09T08:51:32.000Z">2020-06-09</time><span class="level-item"><a class="link-muted" href="/categories/SOTA-Analysis/">SOTA Analysis</a></span><span class="level-item">21 分钟 读完 (大约 3094 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">BiLSTM-CRF模型代码分析及CRF回顾</h1><div class="content"><ul><li>项目介绍：转自<a href="https://zhuanlan.zhihu.com/p/97676647?utm_source=qq&utm_medium=social&utm_oi=1111261179036643329">手撕 BiLSTM-CRF</a>，学习BiLSTM-CRF的数学原理，分析代码结构。</li><li>项目地址：<a href="https://gist.github.com/JovenChu/3386e7710ba61be4e7fc517959326172">https://gist.github.com/JovenChu/3386e7710ba61be4e7fc517959326172</a></li></ul><a id="more"></a><h1 id="BiLSTM-CRF的模型及代码分析"><a href="#BiLSTM-CRF的模型及代码分析" class="headerlink" title="BiLSTM-CRF的模型及代码分析"></a>BiLSTM-CRF的模型及代码分析</h1><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><ol><li><p>结构描述如下：</p><ul><li><p><code>__main__</code> 主流程：构造训练数据集和模型对象</p></li><li><p>模型训练</p></li><li><ul><li>求loss <code>neg_log_likelihood()</code></li><li>CRF的分子 <code>_score_sentence()</code></li><li>CRF的分母 <code>_forward_alg()</code>; 顺便介绍用到的<code>log_sum_exp()</code></li></ul></li><li><p>模型推断：前向运算 <code>forward()</code>，其中涉及维特比解码 <code>_viterbi_decode()</code></p></li></ul></li><li><p>代码结构如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_sum_exp</span><span class="params">(smat)</span>:</span> <span class="comment"># 模型中经常用到的一种路径运算的实现</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiLSTM_CRF</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">neg_log_likelihood</span><span class="params">(self, words, tags)</span>:</span>  <span class="comment"># 求负对数似然，作为loss</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_score_sentence</span><span class="params">(self, frames, tags)</span>:</span> <span class="comment"># 求路径pair: frames-&gt;tags 的分值</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_forward_alg</span><span class="params">(self, frames)</span>:</span> <span class="comment"># 求CRF中的分母"Z", 用于loss</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_viterbi_decode</span><span class="params">(self, frames)</span>:</span> <span class="comment"># 求最优路径分值 和 最优路径</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, words)</span>:</span>  <span class="comment"># 模型inference逻辑</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  	<span class="comment"># 准备好训练数据和模型</span></span><br><span class="line">    training_data = [...]</span><br><span class="line">    model = BiLSTM_CRF(...)</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># 初始化优化器并开始模型训练</span></span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, weight_decay=<span class="number">1e-4</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">300</span>): <span class="comment"># 训练300个epoch</span></span><br><span class="line">        <span class="keyword">for</span> words, tags <span class="keyword">in</span> training_data:</span><br><span class="line">          	<span class="comment"># PyTorch默认会累积梯度; 而我们需要每条样本单独算梯度</span></span><br><span class="line">            model.zero_grad()</span><br><span class="line">            <span class="comment"># 前向求出负对数似然(loss); 然后回传梯度</span></span><br><span class="line">            model.neg_log_likelihood(words, tags).backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">    <span class="comment"># 观察训练后的inference结果</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): print(model(training_data[<span class="number">0</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure></li></ol><h2 id="模型训练逻辑分析——BiLSTM-CRF"><a href="#模型训练逻辑分析——BiLSTM-CRF" class="headerlink" title="模型训练逻辑分析——BiLSTM_CRF"></a>模型训练逻辑分析——BiLSTM_CRF</h2><ol><li><p>总函数——求负对数似然，作为模型Loss函数</p><ul><li><p>函数：<code>neg_log_likelihood</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neg_log_likelihood</span><span class="params">(self, words, tags)</span>:</span>  </span><br><span class="line">  	<span class="string">"""求一对 &lt;sentence, tags&gt; 在当前参数下的负对数似然，作为loss"""</span></span><br><span class="line">    frames = self._get_lstm_features(words)  <span class="comment"># emission score at each frame</span></span><br><span class="line">    gold_score = self._score_sentence(frames, tags)  <span class="comment"># 正确路径的分数</span></span><br><span class="line">    forward_score = self._forward_alg(frames)  <span class="comment"># 所有路径的分数和</span></span><br><span class="line">    <span class="comment"># -(正确路径的分数 - 所有路径的分数和）;注意取负号 -log(a/b) = -[log(a) - log(b)] = log(b) - log(a)</span></span><br><span class="line">    <span class="keyword">return</span> forward_score - gold_score</span><br></pre></td></tr></table></figure></li><li><p>算法步骤：</p><ul><li>首先使用LSTM求出了每一帧对应到每种tag的”发射【分值】矩阵” <code>frames</code> (注意不是【概率】！！！ 这里加起来和不为1；注意CRF跟HMM/MEMM的区别)</li><li>然后，基于<code>frames</code>和当前的CRF层参数，可以求出指定隐状态路径<code>tags</code>对应的分值<code>gold_score</code></li><li>然后，不限定隐状态路径，求出所有路径对应分值之和 <code>forward_score</code></li><li>最后，<strong>根据CRF模型定义：<code>-(正确路径的分数 - 所有路径的分数和）</code></strong>，两者相减即可</li></ul></li></ul></li><li><p>求CRF的分子对数<code>gold_score</code></p><ul><li><p>函数：<code>_score_sentence()</code>，求解正确隐状态的路径分数，即表达式：<img src="https://www.zhihu.com/equation?tex=%5Clog%5Cleft%28%5CPsi%28tags%2Cwords%29%5Cright%29" alt="[公式]"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_score_sentence</span><span class="params">(self, frames, tags)</span>:</span></span><br><span class="line">    tags_tensor = self._to_tensor([START_TAG] + tags, self.tag2ix)</span><br><span class="line">    score = torch.zeros(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i, frame <span class="keyword">in</span> enumerate(frames):  <span class="comment"># 沿途累加每一帧的转移和发射</span></span><br><span class="line">        score += self.transitions[tags_tensor[i], tags_tensor[i + <span class="number">1</span>]] + frame[tags_tensor[i + <span class="number">1</span>]]</span><br><span class="line">    <span class="comment"># 加上到END_TAG的转移</span></span><br><span class="line">    <span class="keyword">return</span> score + self.transitions[tags_tensor[<span class="number">-1</span>], self.tag2ix[END_TAG]]</span><br></pre></td></tr></table></figure></li><li><p>算法公式：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm4v19qdtj30nx03dmyz.jpg" alt="image-20200609164815276"></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm4va5qecj30ef022wez.jpg" alt="image-20200609164829817"></p></li></ul></li><li><p>求CRF的分母 <code>forward_score</code></p><ul><li><p>函数：<code>_forward_alg()</code>，求解所有路径的分数和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_forward_alg</span><span class="params">(self, frames)</span>:</span></span><br><span class="line">    <span class="string">""" 给定每一帧的发射分值; 按照当前的CRF层参数算出所有可能序列的分值和，用作概率归一化分母 """</span></span><br><span class="line">    alpha = torch.full((<span class="number">1</span>, self.n_tags), <span class="number">-10000.0</span>)</span><br><span class="line">    alpha[<span class="number">0</span>][self.tag2ix[START_TAG]] = <span class="number">0</span>  <span class="comment"># 初始化分值分布. START_TAG是log(1)=0, 其他都是很小的值 "-10000"</span></span><br><span class="line">    <span class="keyword">for</span> frame <span class="keyword">in</span> frames:</span><br><span class="line">        <span class="comment"># log_sum_exp()内三者相加会广播: 当前各状态的分值分布(列向量) + 发射分值(行向量) + 转移矩阵(方形矩阵)</span></span><br><span class="line">        <span class="comment"># 相加所得矩阵的物理意义见log_sum_exp()函数的注释; 然后按列求log_sum_exp得到行向量</span></span><br><span class="line">        alpha = log_sum_exp(alpha.T + frame.unsqueeze(<span class="number">0</span>) + self.transitions)</span><br><span class="line">    <span class="comment"># 最后转到EOS，发射分值为0，转移分值为列向量 self.transitions[:, [self.tag2ix[END_TAG]]]</span></span><br><span class="line">    <span class="keyword">return</span> log_sum_exp(alpha.T + <span class="number">0</span> + self.transitions[:, [self.tag2ix[END_TAG]]]).flatten()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_sum_exp</span><span class="params">(smat)</span>:</span></span><br><span class="line">  	<span class="string">"""</span></span><br><span class="line"><span class="string">  	【计算相关的路径】</span></span><br><span class="line"><span class="string">  	代码只有两行，但是涉及二维张量的变形有点晦涩，逐步分析如下, 例如:</span></span><br><span class="line"><span class="string">    smat = [[ 1  3  9]</span></span><br><span class="line"><span class="string">            [ 2  9  1]</span></span><br><span class="line"><span class="string">            [ 3  4  7]]</span></span><br><span class="line"><span class="string">    smat.max(dim=0, keepdim=True) 是指【找到各列的max】，即: vmax = [[ 3  9  9]] 是行向量</span></span><br><span class="line"><span class="string">    然后 smat-vmax, 两者形状分别是 (3,3) 和 (1,3), 相减会广播(vmax广播复制为3*3矩阵)，得到:</span></span><br><span class="line"><span class="string">    smat - vmax = [[ -2  -6  0 ]</span></span><br><span class="line"><span class="string">                   [ -1  0   -8]</span></span><br><span class="line"><span class="string">                   [ 0   -5  -2]]</span></span><br><span class="line"><span class="string">    然后.exp()是逐元素求指数</span></span><br><span class="line"><span class="string">    然后.sum(axis=0, keepdim=True) 是"sum over axis 0"，即【逐列求和】, 得到的是行向量，shape=(1,3)</span></span><br><span class="line"><span class="string">    然后.log()是逐元素求对数</span></span><br><span class="line"><span class="string">    最后再加上 vmax; 两个行向量相加, 结果还是个行向量</span></span><br><span class="line"><span class="string">  	"""</span></span><br><span class="line">  	vmax = smat.max(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>).values  <span class="comment"># 每一列的最大数</span></span><br><span class="line">    <span class="keyword">return</span> (smat - vmax).exp().sum(axis=<span class="number">0</span>, keepdim=<span class="literal">True</span>).log() + vmax</span><br></pre></td></tr></table></figure></li><li><p>算法公式及其推导</p><ul><li><p>分母对数</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%E5%88%86%E6%AF%8D%E5%AF%B9%E6%95%B0+%3D+%5Clog%5Cleft%5B+%5Csum_%7B%5Cmathbf%7Bt%7D+%5Cin+%5Ctext%7BAllPath%7D%7D++%5Cexp%5Cleft%28+%5CPsi%28%5Cmathbf%7Bt%7D%2C+%5Ctext%7Bwords%7D%29+%5Cright%29+%5Cright%5D+%5Cend%7Baligned%7D" alt="[公式]"></p></li><li><p>构建递推关系</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm4vyik15j30kn0a941w.jpg" alt="image-20200609164908566"></p></li><li><p>将单个状态【矩阵化】，并进行广播相加：当前各状态的分值分布(列向量) + 发射分值(行向量) + 转移矩阵(方形矩阵)</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm4wdfymsj30lf0cy0wd.jpg" alt="image-20200609164932526"></p></li></ul></li></ul></li></ol><h2 id="模型推断预测：CRF路径分数的核心"><a href="#模型推断预测：CRF路径分数的核心" class="headerlink" title="模型推断预测：CRF路径分数的核心"></a>模型推断预测：CRF路径分数的核心</h2><ol><li><p>核心逻辑：</p><ul><li><p>过一遍LSTM拿到每一帧的发射状态分布</p></li><li><p>跑viterbi解码得出最优路径和分值。</p></li><li><p>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, words)</span>:</span>  <span class="comment"># 模型inference逻辑</span></span><br><span class="line">    lstm_feats = self._get_lstm_features(words)  <span class="comment"># 求出每一帧的发射矩阵</span></span><br><span class="line">    <span class="keyword">return</span> self._viterbi_decode(lstm_feats)  <span class="comment"># 采用已经训好的CRF层, 做维特比解码, 得到最优路径及其分数</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>求出每一帧的发射状态</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_lstm_features</span><span class="params">(self, words)</span>:</span>  <span class="comment"># 求出每一帧对应的隐向量</span></span><br><span class="line">  <span class="comment"># LSTM输入形状(seq_len, batch=1, input_size); 教学演示 batch size 为1</span></span><br><span class="line">  embeds = self.word_embeds(self._to_tensor(words, self.word2ix)).view(len(words), <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">  <span class="comment"># 随机初始化LSTM的隐状态H</span></span><br><span class="line">  hidden = torch.randn(<span class="number">2</span>, <span class="number">1</span>, self.hidden_dim // <span class="number">2</span>), torch.randn(<span class="number">2</span>, <span class="number">1</span>, self.hidden_dim // <span class="number">2</span>)</span><br><span class="line">  lstm_out, _hidden = self.lstm(embeds, hidden)</span><br><span class="line">  <span class="comment"># 把LSTM输出的隐状态张量去掉batch维，然后降维到tag空间</span></span><br><span class="line">  <span class="keyword">return</span> self.hidden2tag(lstm_out.squeeze(<span class="number">1</span>))</span><br></pre></td></tr></table></figure></li><li><p>维特比解码</p><ul><li><p>函数：<code>_viterbi_decode()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_viterbi_decode</span><span class="params">(self, frames)</span>:</span></span><br><span class="line"> 		<span class="comment"># 回溯路径;  backtrace[i][j] := 第i帧到达j状态的所有路径中, 得分最高的那条在i-1帧是神马状态</span></span><br><span class="line">    backtrace = []</span><br><span class="line">    alpha = torch.full((<span class="number">1</span>, self.n_tags), <span class="number">-10000.</span>)</span><br><span class="line">    alpha[<span class="number">0</span>][self.tag2ix[START_TAG]] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> frame <span class="keyword">in</span> frames:</span><br><span class="line">      <span class="comment"># 这里跟 _forward_alg()稍有不同: 需要求最优路径（而非一个总体分值）, 所以还要对smat求column_max</span></span><br><span class="line">      smat = alpha.T + frame.unsqueeze(<span class="number">0</span>) + self.transitions</span><br><span class="line">      backtrace.append(smat.argmax(<span class="number">0</span>))  <span class="comment"># 当前帧每个状态的最优"来源"</span></span><br><span class="line">      <span class="comment"># 转移规律跟 _forward_alg()一样; 只不过转移之前拿smat求了一下回溯路径</span></span><br><span class="line">      alpha = log_sum_exp(smat)  </span><br><span class="line"></span><br><span class="line">      <span class="comment"># 回溯路径</span></span><br><span class="line">      smat = alpha.T + <span class="number">0</span> + self.transitions[:, [self.tag2ix[END_TAG]]]</span><br><span class="line">      best_tag_id = smat.flatten().argmax().item()</span><br><span class="line">      best_path = [best_tag_id]</span><br><span class="line">      <span class="keyword">for</span> bptrs_t <span class="keyword">in</span> reversed(backtrace[<span class="number">1</span>:]):  <span class="comment"># 从[1:]开始，去掉开头的 START_TAG</span></span><br><span class="line">        best_tag_id = bptrs_t[best_tag_id].item()</span><br><span class="line">        best_path.append(best_tag_id)</span><br><span class="line">        <span class="keyword">return</span> log_sum_exp(smat).item(), best_path[::<span class="number">-1</span>]  <span class="comment"># 返回最优路径分值 和 最优路径</span></span><br></pre></td></tr></table></figure></li><li><p>定义：</p><ul><li>是一个通用的<strong>求序列最短路径</strong>的方法。可用于隐式马尔科夫模型HMM解码算法，最优分词等。</li><li>给定条件随机场（CRF）的条件概率 𝑃(𝑦|𝑥) 和一个观测序列 𝑥 ,要求出满足 𝑃(𝑦|𝑥) 最大的序列𝑦。</li><li>本身是一个动态规划算法，利用了两个局部状态和对应的递推公式，从局部递推到整体，进而得解。对于具体不同的问题，仅仅是这两个局部状态的定义和对应的递推公式不同而已。</li></ul></li><li><p>算法流程：<a href="https://www.cnblogs.com/pinard/p/7068574.html">参考链接</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm4m1n3p8j30oa0hkmz6.jpg" alt="image-20200609163934259"></p></li><li><p>维特比解码与前向求CRF分母对数时的区别：这里除了要迭代更新 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 以外，还要追踪每一帧的每个状态的最优“上一步”来自于哪里。</p></li></ul></li></ol><h2 id="CRF回顾——原文"><a href="#CRF回顾——原文" class="headerlink" title="CRF回顾——原文"></a>CRF回顾——<a href="https://spaces.ac.cn/archives/5542/comment-page-1">原文</a></h2><ol><li><a href="https://spaces.ac.cn/archives/4695">逐帧softmax</a>：CRF主要用于序列标注问题，可以简单理解为是给序列中的每一帧都进行分类，既然是分类，很自然想到将这个序列用CNN或者RNN进行编码后，接一个全连接层用softmax激活。设计标签时，目标输出序列本身是带有上下文关联信息的（比如BIO标注法中，I不能是一个实体的开头），而逐帧的softmax不会考虑到这些。</li></ol><ul><li><ol start="2"><li>CRF：（1）将输出层面的关联分离了出来；（2）<strong>以路径为单位，考虑的是路径的概率</strong>。</li></ol><ul><li><p>假如一个输入有n帧，每一帧的标签有k种可能性，那么理论上就有k的n次方种不同的输出。而逐帧softmax和CRF的根本不同就是：<strong>前者将序列标注看成是n个k分类问题，后者将序列标注看成是1个k的n次方分类问题。</strong></p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9diso3u6ij30j1071gob.jpg" alt="4tag分词模型中输出网络图"></p></li><li><p>CRF的条件概率：</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dj2blb9hj30hf02ddg2.jpg" alt="image-20191128100731942"></p></li><li><p>CRF的两个假设：</p><ul><li><p><strong>假设一</strong> 该分布是指数族分布。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dixnc287j30hq0510td.jpg" alt="image-20191128100302661"></p></li><li><p><strong>假设二</strong> 输出之间的关联仅发生在相邻位置，并且关联是指数加性的。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9diy0fg6sj30hw050gm8.jpg" alt="image-20191128100324788"></p></li></ul></li><li><p>线性链CRF：考虑到当前深度学习模型中，RNN或者层叠CNN等模型已经能够比较充分捕捉各个y与输入<strong>x</strong>的联系，因此，我们不妨考虑函数g跟<strong>x</strong>无关，那么：</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dj1417snj30hn06g0tk.jpg" alt="image-20191128100622771"></p></li><li><p>归一化因子：在物理上也叫配分函数，在这里它需要我们对所有可能的路径的打分进行指数求和，而我们前面已经说到，这样的路径数是指数量级的（k的n次方），因此直接来算几乎是不可能的。事实上，归一化因子难算，几乎是所有概率图模型的公共难题。幸运的是，在CRF模型中，由于我们只考虑了临近标签的联系（马尔可夫假设），因此我们可以递归地算出归一化因子，这使得原来是指数级的计算量降低为线性级别。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dkgkj0phj30hl05twez.jpg" alt="image-20191128105549674"></p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dkhiaaavj30hq0f9tb6.jpg" alt="image-20191128105644179"></p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dkipq07xj30mu0ewn0u.jpg" alt="归一化因子的递归计算图示。从t到t+1时刻的计算，包括转移概率和j+1节点本身的概率" style="zoom:67%"></li><li><p><a href="https://kexue.fm/archives/3842">动态规划</a>：写出损失函数−logP(y1,…,yn|<strong>x</strong>)后，就可以完成模型的训练了，因为目前的深度学习框架都已经带有自动求导的功能，只要我们能写出可导的loss，就可以帮我们完成优化过程了。</p><p>那么剩下的最后一步，就是模型训练完成后，如何根据输入找出最优路径来。跟前面一样，这也是一个从<strong>k的n次方</strong>条路径中选最优的问题，而同样地，因为马尔可夫假设的存在，它可以转化为一个动态规划问题，用viterbi算法解决，计算量正比于n。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9dkpli761j30hj07hq4r.jpg" alt="image-20191128110430186"></p><p><strong>动态规划的递归思想就是：一条最优路径切成两段，那么每一段都是一条（局部）最优路径。</strong></p></li></ul></li></ul></div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/BiLSTM/">BiLSTM</a><a class="link-muted mr-2" rel="tag" href="/tags/CRF/">CRF</a><a class="link-muted mr-2" rel="tag" href="/tags/NER/">NER</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP-Model-Analysis/">NLP Model Analysis</a></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><div class="social-share"></div><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><ul class="post-copyright"><li><strong>本文标题：</strong><a href="https://jovenchu.github.io/2020/06/09/2020-06-09-BiLSTM-CRF/">BiLSTM-CRF模型代码分析及CRF回顾</a></li><li><strong>本文作者：</strong><a href="https://jovenchu.github.io">Joven Chu</a></li><li><strong>本文链接：</strong><a id="artTitle" href="https://jovenchu.github.io/2020/06/09/2020-06-09-BiLSTM-CRF/">https://jovenchu.github.io/2020/06/09/2020-06-09-BiLSTM-CRF/</a></li><li><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</span></li></ul><script>window.onload=function(){var n=window.document.location.href,t=window.document.location.pathname,o=n.indexOf(t),i=n.substring(0,o),a=$("#artTitle").html().substring(25);$("#artTitle").html(i+"/"+a)}</script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay.jpg" alt="支付宝"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechatpay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/07/16/2020-07-16-Chinese-Couplet/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">基于Seq2Seq的中文对联生成模型</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/10/22/2019-10-22-Information-Extraction-Chinese/"><span class="level-item">基于Bert-NER构建特定领域的中文信息抽取框架</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config=function(){this.page.url="https://jovenchu.github.io/2020/06/09/2020-06-09-BiLSTM-CRF/",this.page.identifier="2020/06/09/2020-06-09-BiLSTM-CRF/"};!function(){var e=document,t=e.createElement("script");t.src="//jovenchu.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}()</script></div></div></div><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen order-3"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#BiLSTM-CRF的模型及代码分析"><span class="mr-2">1</span><span>BiLSTM-CRF的模型及代码分析</span></a><ul class="menu-list"><li><a class="is-flex" href="#模型结构"><span class="mr-2">1.1</span><span>模型结构</span></a></li><li><a class="is-flex" href="#模型训练逻辑分析——BiLSTM-CRF"><span class="mr-2">1.2</span><span>模型训练逻辑分析——BiLSTM_CRF</span></a></li><li><a class="is-flex" href="#模型推断预测：CRF路径分数的核心"><span class="mr-2">1.3</span><span>模型推断预测：CRF路径分数的核心</span></a></li><li><a class="is-flex" href="#CRF回顾——原文"><span class="mr-2">1.4</span><span>CRF回顾——原文</span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img src="/images/jovens.png" alt="Joven Chu"></figure><p class="title is-size-4 is-block line-height-inherit">Joven Chu</p><p class="is-size-6 is-block">The Alchemist of AI</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shenzhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JovenChu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/JovenChu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/profile.php?id=100009189950558"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/Qomolangma03"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/jovenchu233/"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget"><link href="/music/APlayer.min.css"><div id="aplayer" style="margin:0 auto"></div><script src="/music/APlayer.min.js"></script><script src="/music/APlayer_Music.js"></script></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><a class="media-left" href="/2020/07/16/2020-07-16-Chinese-Couplet/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggsw3l7ybwj31400u0kjl.jpg" alt="基于Seq2Seq的中文对联生成模型"></p></a><div class="media-content size-small"><p><time datetime="2020-07-16T08:14:18.000Z">2020-07-16</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/16/2020-07-16-Chinese-Couplet/">基于Seq2Seq的中文对联生成模型</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Text-Generation/">Text Generation</a></p></div></article><article class="media"><a class="media-left" href="/2020/06/09/2020-06-09-BiLSTM-CRF/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfm5d5m5koj318z0u0b2a.jpg" alt="BiLSTM-CRF模型代码分析及CRF回顾"></p></a><div class="media-content size-small"><p><time datetime="2020-06-09T08:51:32.000Z">2020-06-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/09/2020-06-09-BiLSTM-CRF/">BiLSTM-CRF模型代码分析及CRF回顾</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/SOTA-Analysis/">SOTA Analysis</a></p></div></article><article class="media"><a class="media-left" href="/2019/10/22/2019-10-22-Information-Extraction-Chinese/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/006y8mN6gy1g86qm6jxacj30rs0ij75k.jpg" alt="基于Bert-NER构建特定领域的中文信息抽取框架"></p></a><div class="media-content size-small"><p><time datetime="2019-10-22T01:39:47.000Z">2019-10-22</time></p><p class="title is-6"><a class="link-muted" href="/2019/10/22/2019-10-22-Information-Extraction-Chinese/">基于Bert-NER构建特定领域的中文信息抽取框架</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Information-Extraction/">Information Extraction</a></p></div></article><article class="media"><a class="media-left" href="/2019/10/17/2019-10-17-AutoNLP-Analysis/"><p class="image is-64x64"><img class="thumbnail" src="https://images.unsplash.com/reserve/L55hYy77SLqb6zeTMlWr_IMG_9035.jpg?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1000&amp;q=80" alt="AutoNLP_Analysis"></p></a><div class="media-content size-small"><p><time datetime="2019-10-17T06:55:58.000Z">2019-10-17</time></p><p class="title is-6"><a class="link-muted" href="/2019/10/17/2019-10-17-AutoNLP-Analysis/">AutoNLP_Analysis</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/AutoNLP/">AutoNLP</a></p></div></article><article class="media"><a class="media-left" href="/2019/10/11/2019-10-11-Knowledge-Graph-Bert/"><p class="image is-64x64"><img class="thumbnail" src="https://tva1.sinaimg.cn/large/006y8mN6gy1g7u2cla0jsj31h90u0x6r.jpg" alt="Knowledge_Graph_Bert"></p></a><div class="media-content size-small"><p><time datetime="2019-10-11T02:45:08.000Z">2019-10-11</time></p><p class="title is-6"><a class="link-muted" href="/2019/10/11/2019-10-11-Knowledge-Graph-Bert/">Knowledge_Graph_Bert</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Knowledge-Graph/">Knowledge Graph</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/AutoNLP/"><span class="level-start"><span class="level-item">AutoNLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ElasticSearch/"><span class="level-start"><span class="level-item">ElasticSearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Information-Extraction/"><span class="level-start"><span class="level-item">Information Extraction</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Knowledge-Graph/"><span class="level-start"><span class="level-item">Knowledge Graph</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="level-start"><span class="level-item">NLP基础知识</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/SOTA-Analysis/"><span class="level-start"><span class="level-item">SOTA Analysis</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Text-Generation/"><span class="level-start"><span class="level-item">Text Generation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%AD%A6%E4%B9%A0%E5%8D%9A%E5%AE%A2/"><span class="level-start"><span class="level-item">学习博客</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item">对话系统</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">七月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">六月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/09/"><span class="level-start"><span class="level-item">九月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Joven Chu Blog" height="28"></a><p class="size-small">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> base on <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a></p></div><div class="level-mid"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/JovenChu"><i class="fab fa-github"></i></a></p></div></div><div class="level-end"><p class="size-small"><span><span id="statistic-times">loading...</span><script>function createTime(n){var m=new Date(n);now.setTime(now.getTime()+250),days=(now-m)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-m)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-m)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-m)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("statistic-times").innerHTML="♥ Security Run For <strong>"+dnum+"</strong> Days <strong>"+hnum+"</strong> Hours <strong>"+mnum+"</strong> Min <strong>"+snum+"</strong> Sec ♥"}var now=new Date;setInterval("createTime('12/31/2018 00:00:00')",250,"")</script><br></span></p><div class="size-small"><span>♥ Thanks For <strong><span id="busuanzi_value_site_uv">99+</span></strong> Visitors Come To My Site ♥</span></div><p></p></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN")</script><script>var IcarusThemeSettings={site:{url:"https://jovenchu.github.io",external_link:{enable:!0,exclude:[]}},article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><canvas class="fireworks" width="100%" height="100%" style="position:fixed;left:0;top:0;z-index:99999999;pointer-events:none"></canvas><script src="/js/anime.min.js" defer></script><script src="/js/fireworks.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script src="/js/main.js" defer></script><script src="/js/universe.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"想要查找什么...",untitled:"(无标题)",posts:"文章",pages:"页面",categories:"分类",tags:"标签"})})</script></body></html><!-- rebuild by neat -->